{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cdd5dff9",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "193c5f00",
   "metadata": {},
   "source": [
    "## Check Python version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72a1daa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from platform import  python_version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5008ff37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.10.5'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "python_version()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c1e161",
   "metadata": {},
   "source": [
    "## Install/Download necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fad5b9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f94128ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Uncomment these if any packages are not installed in your current jupyter env \n",
    "# # Installing a pip package in the current kernel\n",
    "# # Pandas also installs the numpy package\n",
    "# !{sys.executable} -m pip install pandas  \n",
    "# !{sys.executable} -m pip install requests\n",
    "# !{sys.executable} -m pip install matplotlib\n",
    "# !{sys.executable} -m pip install sklearn\n",
    "# !{sys.executable} -m pip install featuretools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20d8ab7c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import the required packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import sklearn\n",
    "import os\n",
    "import datetime as dt\n",
    "import featuretools as ft\n",
    "from featuretools.selection import selection "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cdaf39f",
   "metadata": {},
   "source": [
    "# Importing and Preprocessing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "96d4a308",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['20220703_120137530608_RBD.csv',\n",
       " '20220703_120253586011_RBD.xlsx',\n",
       " '20220703_120455835661_RBD.csv',\n",
       " 'AllShares_growth.csv',\n",
       " 'household_financial_assets-currency_and_deposits.csv',\n",
       " 'investment_Qgrowth.csv',\n",
       " 'inv_by_assets_intellectual.csv',\n",
       " 'main.csv',\n",
       " 'mainexcel.xlsx',\n",
       " 'share_prices.csv',\n",
       " 'test1.xlsx',\n",
       " 'test1csv.csv']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def view_files():\n",
    "    path = os.getcwd()\n",
    "    path = f\"{path}\\data\"\n",
    "    return(os.listdir(path))\n",
    "\n",
    "files = view_files()\n",
    "files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48515b49",
   "metadata": {},
   "source": [
    "## Importing and Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba05a830",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_file(i):\n",
    "    #grab the file path from which to import the dataset\n",
    "    path = os.getcwd()\n",
    "    path = f\"{path}\\data\"\n",
    "    path = f\"{path}\\{files[i]}\"\n",
    "    return(path)\n",
    "\n",
    "def import_data(path):\n",
    "    # read the csv file as a dataframe and remove unnecessary columns\n",
    "    df = pd.read_csv(filepath_or_buffer=path)\n",
    "    return(df)\n",
    "    \n",
    "def clean_data(df, bank_prefix=\"B_34118: \"):\n",
    "    df = df.drop([\"Unit\", \"Time series code\"], axis=\"columns\")\n",
    "    \n",
    "    # Remove ugly string labels of columns\n",
    "    df.columns = df.columns.str.replace(pat=\"D_M_[0-9]{4}M[0-9]{2}:\", repl=\"\", regex=True)\n",
    "    df[\"Bank\"] = df[\"Bank\"].str.replace(pat=bank_prefix, repl=\"\", regex=True)\n",
    "    df[\"Bank\"] = df[\"Bank\"].str.replace(pat = \" \", repl = \"_\")\n",
    "    # Remove empty title rows\n",
    "    df = df[~df[\"Table\"].str.contains(\"T_T[0-9]{2}R[0-9]{3}:\", regex = True)]\n",
    "    df = df[~df[\"Table\"].str.contains(\"T_T[0-9]{2}R[0-9]{3}_A:\", regex = True)]\n",
    "    # Label the different tables withing the df, i.e liablities, assets, etc.\n",
    "    df[\"Table\"] = df[\"Table\"].str.replace(\"T_T0[0-4]R[0-9]{3,4}C[0-9]{2}: T0[1-4]R[0-9]{3}[A]{0,1}C[0-9]{2}: \", \n",
    "                                          regex = True, repl=\"L_\")\n",
    "    df[\"Table\"] = df[\"Table\"].str.replace(\"T_T0[5]R[0-9]{3,4}C[0-9]{2}: T0[5]R[0-9]{3}[A]{0,1}C[0-9]{2}: \", \n",
    "                                      regex = True, repl=\"E_\")\n",
    "    df[\"Table\"] = df[\"Table\"].str.replace(\"T_T0[6-9]R[0-9]{3,4}C[0-9]{2}: T0[6-9]R[0-9]{3}[A]{0,1}C[0-9]{2}: \", \n",
    "                                          regex = True, repl=\"A_\")\n",
    "    df[\"Table\"] = df[\"Table\"].str.replace(\"T_T1[0-3]R[0-9]{3,4}C[0-9]{2}: T1[0-3]R[0-9]{3}[A]{0,1}C[0-9]{2}: \", \n",
    "                                          regex = True, repl=\"A_\")\n",
    "    \n",
    "    df[\"Table\"] = df[\"Table\"].str.replace(\"[(][0-9a-z\\s,]{2,}[)][:] \", regex = True, repl=\"\")\n",
    "    #\n",
    "    df = df.set_index(\"Table\").T.drop(\"Bank\")\n",
    "    df.index = pd.to_datetime(df.index, format=\" %YM%m\")\n",
    "    df.dropna(axis=1, inplace=True)\n",
    "    df.columns = df.columns.str.replace(pat=\" \", repl=\"_\")\n",
    "    df = df.apply(pd.to_numeric)\n",
    "    df = ft.selection.remove_highly_null_features(df)\n",
    "    df = ft.selection.remove_single_value_features(df)\n",
    "    df = df.loc[:,~df.columns.duplicated()]    \n",
    "    \n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "157f852b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\GitHub\\\\DS_PROJ\\\\data\\\\AllShares_growth.csv'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_file(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ab251de",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>SPASTT01ZAM657N</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1960-02-01</td>\n",
       "      <td>-1.459491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1960-03-01</td>\n",
       "      <td>-7.054686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1960-04-01</td>\n",
       "      <td>-9.074221</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         DATE  SPASTT01ZAM657N\n",
       "0  1960-02-01        -1.459491\n",
       "1  1960-03-01        -7.054686\n",
       "2  1960-04-01        -9.074221"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import_data(check_file(3)).head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57c5f0a",
   "metadata": {},
   "source": [
    "The data is stored in an ugly format, and needs too be transformed and formatted into\n",
    "a more usable form for data analysis\n",
    "Below the data is:\n",
    "* Transformed into the standard dataframe format\n",
    "* Column names are reformatted\n",
    "* Observation types are converted to floats\n",
    "* The date variable is transformed to a datetime object for ease of use\n",
    "* The correct labels for liabilities, assets, and equity is assigned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c3a538b1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['Unit', 'Time series code'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[1;32mIn [10]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m absa \u001b[38;5;241m=\u001b[39m \u001b[43mclean_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimport_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheck_file\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [7]\u001b[0m, in \u001b[0;36mclean_data\u001b[1;34m(df, bank_prefix)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mclean_data\u001b[39m(df, bank_prefix\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mB_34118: \u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m---> 14\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mUnit\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTime series code\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;66;03m# Remove ugly string labels of columns\u001b[39;00m\n\u001b[0;32m     17\u001b[0m     df\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mreplace(pat\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mD_M_[0-9]\u001b[39m\u001b[38;5;132;01m{4}\u001b[39;00m\u001b[38;5;124mM[0-9]\u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m, repl\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m, regex\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\DS_prac\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[0;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[0;32m    310\u001b[0m     )\n\u001b[1;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\DS_prac\\lib\\site-packages\\pandas\\core\\frame.py:4948\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4800\u001b[0m \u001b[38;5;129m@deprecate_nonkeyword_arguments\u001b[39m(version\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, allowed_args\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mself\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m   4801\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop\u001b[39m(\n\u001b[0;32m   4802\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4809\u001b[0m     errors: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   4810\u001b[0m ):\n\u001b[0;32m   4811\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4812\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[0;32m   4813\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4946\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[0;32m   4947\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4948\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   4949\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4950\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4951\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4952\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4953\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4954\u001b[0m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4955\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4956\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\DS_prac\\lib\\site-packages\\pandas\\core\\generic.py:4279\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4277\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m   4278\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 4279\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_drop_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4281\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[0;32m   4282\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\DS_prac\\lib\\site-packages\\pandas\\core\\generic.py:4323\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[1;34m(self, labels, axis, level, errors, consolidate, only_slice)\u001b[0m\n\u001b[0;32m   4321\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   4322\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 4323\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m \u001b[43maxis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4324\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mget_indexer(new_axis)\n\u001b[0;32m   4326\u001b[0m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[0;32m   4327\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\DS_prac\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6644\u001b[0m, in \u001b[0;36mIndex.drop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   6642\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m   6643\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 6644\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(labels[mask])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6645\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[0;32m   6646\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['Unit', 'Time series code'] not found in axis\""
     ]
    }
   ],
   "source": [
    "absa = clean_data(import_data(check_file(3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7282f735",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "absa.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc425c0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4c13983a",
   "metadata": {},
   "source": [
    "Some of the highly overlapping columns are removed now, \n",
    "and others will be removed after the necessary\n",
    "additional features have been calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "98d5f902",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This dataset has a particular problem with overlapping or highly\n",
    "# correlated features that contain elements from other columns\n",
    "# Thus, we remove these highly correlated features\n",
    "\n",
    "def remove_corr(df):\n",
    "    df.reset_index(inplace=True)\n",
    "    es = ft.EntitySet(id=\"Absa_BS\")\n",
    "    ent_set = es.add_dataframe(dataframe_name=\"Absa_Group_Ltd\",\n",
    "                                dataframe=df, \n",
    "                                already_sorted=False, index = \"index\")\n",
    "    \n",
    "    fm, features = ft.dfs(entityset=ent_set,\n",
    "                      target_dataframe_name=\"Absa_Group_Ltd\",\n",
    "                      trans_primitives=[],\n",
    "                      agg_primitives=[], \n",
    "                      max_depth=1)\n",
    "    # From experimentation, the 0.97 threshold seems to remove the \n",
    "    # columns that are verbatim totals of others and not removing\n",
    "    # other columns required for feature analysis.\n",
    "    # A lower threshold will be used at a later stage after some\n",
    "    # columns have been used in calculation of additional \n",
    "    # features\n",
    "    fm = ft.selection.remove_highly_correlated_features(fm, \n",
    "                                                        pct_corr_threshold=0.97)\n",
    "    fm.reset_index(inplace=True)\n",
    "    fm.set_index(\"index\", inplace=True)\n",
    "    fm.columns.name = \"Date\"\n",
    "    fm.index.name = None\n",
    "\n",
    "    return(fm)\n",
    "\n",
    "absa = remove_corr(absa)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e344200d",
   "metadata": {},
   "source": [
    "### Creating the Liquidity Ratio Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c173fb5",
   "metadata": {},
   "source": [
    "Now, we want to create a loan to deposit ratio to create a liquidity ratio variable for the bank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "fcb721f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date\n",
       "L_DEPOSITS_Cheque_(1)                                                                      9588342.0\n",
       "L_DEPOSITS_Savings_(2)                                                                     7800740.0\n",
       "L_DEPOSITS_Up_to_1_day_(3)                                                                 8946659.0\n",
       "L_DEPOSITS_More_than_1_day_to_1_month_(4)                                                  9417927.0\n",
       "L_DEPOSITS_More_than_1_month_to_6_months_(5)                                              21301640.0\n",
       "L_DEPOSITS_More_than_6_months_(6)                                                          8981624.0\n",
       "L_Other_deposits:_More_than_1_day_to_1_month_(4)                                            342393.0\n",
       "L_Other_deposits:_More_than_1_month_to_6_months_(5)                                         435657.0\n",
       "L_Other_deposits:_More_than_6_months_(6)                                                    171516.0\n",
       "L_Other_deposits:_TOTAL_(7)                                                                3876951.0\n",
       "L_Central_and_provincial_government_sector_depositsc_Cheque_(1)                             172572.0\n",
       "L_Central_and_provincial_government_sector_depositsc_Savings_(2)                              5649.0\n",
       "L_Central_and_provincial_government_sector_depositsc_Up_to_1_day_(3)                         25823.0\n",
       "L_Central_and_provincial_government_sector_depositsc_More_than_1_day_to_1_month_(4)         417902.0\n",
       "L_Central_and_provincial_government_sector_depositsc_More_than_1_month_to_6_months_(5)      564171.0\n",
       "L_Central_and_provincial_government_sector_depositsc_More_than_6_months_(6)                  52855.0\n",
       "Name: 1993-01-01 00:00:00, dtype: float64"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "absa.iloc[0,absa.columns.str.contains(\"^L.*deposits\", case=False)]#[1:8]#.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "a8f04bf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date\n",
       "A_Other_deposits_with_and_loans_and_advances_to_SA_banksb:_Domestic_assets_(1)                       501582.0\n",
       "A_Foreign_currency_loans_and_advances_TOTAL_ASSETS_(Col_1_plus_col_3)_(5)                            823789.0\n",
       "A_Overdrafts,_loans_and_advances:_public_sector_Domestic_assets_(1)                                  575480.0\n",
       "A_Overdrafts,_loans_and_advances:_public_sector_TOTAL_ASSETS_(Col_1_plus_col_3)_(5)                  575578.0\n",
       "A_Less:_credit_impairments_in_respect_of_loans_and_advances:_TOTAL_ASSETS_(Col_1_plus_col_3)_(5)    1995422.0\n",
       "Name: 1993-01-01 00:00:00, dtype: float64"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "absa.iloc[0,absa.columns.str.contains(\"LOANS\", case=False, regex=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "e9f34a05",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def create_total_deposits(df_global):\n",
    "    df = df_global\n",
    "    deposits = df.columns.str.contains(\"^L.*deposits\", \n",
    "                                           case=False, \n",
    "                                           regex=True)\n",
    "    drops = list(df.columns[deposits])\n",
    "    df[\"L_TOTAL_DEPOSITS\"] = df.iloc[:,deposits].sum(axis=1)\n",
    "    df = df.drop(columns=drops)\n",
    "    return(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "6dd6424f",
   "metadata": {},
   "outputs": [],
   "source": [
    "absa = create_total_deposits(absa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "2eaa6951",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_total_loans(df_global):\n",
    "    df = df_global\n",
    "    loans = df.columns.str.contains(\"Loans\", \n",
    "                                       case=False, \n",
    "                                       regex=True)\n",
    "    drops = list(df.columns[loans])\n",
    "    df[\"A_TOTAL_LOANS\"] = df.iloc[:,loans].sum(axis=1)\n",
    "    df = df.drop(columns=drops)\n",
    "    return(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "db63f307",
   "metadata": {},
   "outputs": [],
   "source": [
    "absa = create_total_loans(absa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "58272918",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Date</th>\n",
       "      <th>A_TOTAL_LOANS</th>\n",
       "      <th>L_TOTAL_DEPOSITS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1993-01-01</th>\n",
       "      <td>4471851.0</td>\n",
       "      <td>7.210242e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993-02-01</th>\n",
       "      <td>7615276.0</td>\n",
       "      <td>7.023894e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993-03-01</th>\n",
       "      <td>6410475.0</td>\n",
       "      <td>7.228946e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993-04-01</th>\n",
       "      <td>4496268.0</td>\n",
       "      <td>6.939787e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993-05-01</th>\n",
       "      <td>4452967.0</td>\n",
       "      <td>6.757947e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-01</th>\n",
       "      <td>47481729.0</td>\n",
       "      <td>1.199028e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-01</th>\n",
       "      <td>42900565.0</td>\n",
       "      <td>1.153581e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-01</th>\n",
       "      <td>53452861.0</td>\n",
       "      <td>1.172717e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-01</th>\n",
       "      <td>45123231.0</td>\n",
       "      <td>1.185268e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-04-01</th>\n",
       "      <td>53489383.0</td>\n",
       "      <td>1.204658e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>351 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Date        A_TOTAL_LOANS  L_TOTAL_DEPOSITS\n",
       "1993-01-01      4471851.0      7.210242e+07\n",
       "1993-02-01      7615276.0      7.023894e+07\n",
       "1993-03-01      6410475.0      7.228946e+07\n",
       "1993-04-01      4496268.0      6.939787e+07\n",
       "1993-05-01      4452967.0      6.757947e+07\n",
       "...                   ...               ...\n",
       "2021-12-01     47481729.0      1.199028e+09\n",
       "2022-01-01     42900565.0      1.153581e+09\n",
       "2022-02-01     53452861.0      1.172717e+09\n",
       "2022-03-01     45123231.0      1.185268e+09\n",
       "2022-04-01     53489383.0      1.204658e+09\n",
       "\n",
       "[351 rows x 2 columns]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def liquidity_ratio(df):\n",
    "    \n",
    "    \n",
    "\n",
    "absa[[\"A_TOTAL_LOANS\", \"L_TOTAL_DEPOSITS\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e08fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove2 = list()\n",
    "for h in range(len(absa.columns.to_list())):\n",
    "    for i in range(1, round(0.2*len(absa.columns.to_list()))):\n",
    "    if all(round(absa.iloc[:,h], \n",
    "                 ndigits=-2) == round(absa.iloc[:,h+1:i].sum(axis=1), \n",
    "                                      ndigits=-2)):\n",
    "        remove2.extend(absa.iloc[:,h+1:i].columns.to_list())\n",
    "        print(absa.iloc[:,h+1:i].columns.to_list())\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "len(set(remove2)), len(remove2) # The list is unique\n",
    "\n",
    "total_mod_BA900.drop(remove2, axis=1, inplace=True)\n",
    "\n",
    "# remove3 = list()\n",
    "\n",
    "# for h in range(len(total_mod_BA900.columns.to_list())):\n",
    "# for i in range(1,\n",
    "# round(0.5*len(total_mod_BA900.columns.to_list()))):\n",
    "# if all(round(total_mod_BA900.iloc[:,h], ndigits=-2) ==\n",
    "# round(total_mod_BA900.iloc[:,h+1:i].sum(axis=1), ndigits=-2)):\n",
    "# remove3.extend(total_mod_BA900.iloc[:,h+1:i].columns.to_list())\n",
    "# print(total_mod_BA900.iloc[:,h+1:i].columns.to_list())\n",
    "# else:\n",
    "# continuetotal_mod_BA900.drop(remove3, axis=1, inplace=True)remove4 = list()\n",
    "# for h in\n",
    "# range(len(total_mod_BA900.columns.to_list())):\n",
    "# for i in range(1, round(0.5*len(total_mod_BA900.columns.to_list()))):\n",
    "# if\n",
    "# all(round(total_mod_BA900.iloc[:,h], ndigits=-2) == round(total_mod_BA900.iloc[:,h+1:i].sum(axis=1), ndigits=-2)):\n",
    "# remove4.extend(total_mod_BA900.iloc[:,h+1:i].columns.to_list())\n",
    "# print(total_mod_BA900.iloc[:,h+1:i].columns.to_list())\n",
    "# else:\n",
    "# continuetotal_mod_BA900.drop(remove4, axis=1, inplace=True) #.filter(regex=\"L_OtherDomestic[AA-Zaz_]*_\n",
    "# Total\")[\"L_OtherDomestic_Total\"]remove5 = list()\n",
    "# for h in range(len(total_mod_BA900.columns.to_list())):\n",
    "# for i in\n",
    "# range(1, round(0.25*len(total_mod_BA900.columns.to_list()))):\n",
    "# if all(round(total_mod_BA900.iloc[:,h], ndigits=-2) ==\n",
    "# round(total_mod_BA900.iloc[:,h+1:i].sum(axis=1), ndigits=-2)):\n",
    "# remove5.extend(total_mod_BA900.iloc[:,h+1:i].columns.to_list())\n",
    "# print(total_mod_BA900.iloc[:,h+1:i].columns.to_list())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a30f2e3",
   "metadata": {},
   "source": [
    "some of these columns seem to appear 'twice' and will therefore be removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19853d9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315e2170",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21776896",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0834bfa7",
   "metadata": {},
   "source": [
    "## Removing Highly Correlated Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14289deb",
   "metadata": {},
   "source": [
    "This dataset contains groups of variables that sum together to form larger aggregates. To ensure\n",
    "that the model only uses features that are relevant once, we remove a subset of those features that\n",
    "are too highly correlated with others. This would also introduce the issue of multicolinearity if the\n",
    "features are not removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f10dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This dataset has a particular problem with overlapping or highly\n",
    "# correlated features that contain elements from other columns\n",
    "# Thus, we remove these highly correlated features\n",
    "\n",
    "def remove_corr(df):\n",
    "    df.reset_index(inplace=True)\n",
    "    es = ft.EntitySet(id=\"Absa_BS\")\n",
    "    ent_set = es.add_dataframe(dataframe_name=\"Absa_Group_Ltd\",\n",
    "                                dataframe=df, \n",
    "                                already_sorted=False, index = \"index\")\n",
    "    \n",
    "    fm, features = ft.dfs(entityset=ent_set,\n",
    "                      target_dataframe_name=\"Absa_Group_Ltd\",\n",
    "                      trans_primitives=[],\n",
    "                      agg_primitives=[], \n",
    "                      max_depth=1)\n",
    "    # From experimentation, the 0.9825 threshold seems to remove the \n",
    "    # columns that are verbatim totals of others\n",
    "    # A lower threshold will be used at a later stage after some\n",
    "    # columns have been used in calculation of additional \n",
    "    # features\n",
    "    fm = ft.selection.remove_highly_correlated_features(fm, \n",
    "                                                        pct_corr_threshold=0.9825)\n",
    "    fm.reset_index(inplace=True)\n",
    "    fm.set_index(\"index\", inplace=True)\n",
    "    fm.columns.name = \"Date\"\n",
    "    fm.index.name = None\n",
    "\n",
    "    return(fm)\n",
    "\n",
    "absa = remove_corr(absa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27070df",
   "metadata": {},
   "outputs": [],
   "source": [
    "absa.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e73d95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a75b85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb0f01b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5ec60c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
